{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "registered-taste",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:90% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import csv\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "import math\n",
    "from scipy.optimize import minimize, LinearConstraint\n",
    "import matplotlib.ticker as mtick\n",
    "import scipy.optimize\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:90% !important; }</style>\"))\n",
    "from scipy.stats import beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "executed-priest",
   "metadata": {},
   "outputs": [],
   "source": [
    "def factorial(n):\n",
    "    if n == 0:\n",
    "        return 1\n",
    "    else:\n",
    "        return n * factorial(n-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "danish-adolescent",
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_function2():\n",
    "    print(\"This is a function without arguments\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "crucial-advice",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_function2()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "automatic-somewhere",
   "metadata": {},
   "source": [
    "Below has four cost classes, not five"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "passive-chick",
   "metadata": {},
   "outputs": [],
   "source": [
    "spec = 1000000 # Number specified as rounded up to nearest log10 integer from max(HaggLQ)\n",
    "xxx = np.linspace(1,spec, num=spec) # Array of 1 to 10000, as integers\n",
    "xxx = np.log10(xxx) # Finds logs of above values, should be 1 to 4\n",
    "xxx2 = np.linspace(0,max(xxx),num=int(max(xxx)*3+1)) # Breaking up into x bins per log 10\n",
    "xxx3=10**xxx2 # Creating actual bin bound values\n",
    "xxx4 = xxx3.tolist()\n",
    "xxx4[0] = xxx4[0]-1.01\n",
    "\n",
    "# Create bins of damage level labels and sort events into Bins\n",
    "damage_cut_labels = [0,1,2,3,4]\n",
    "# Minimum bin edge must be slightly less than 0 to account for dollars damage =0\n",
    "damage_cut_bins = [-0.1, 1000, 1000000, 10000000, 100000000, 1000000000]\n",
    "\n",
    "\n",
    "df = pd.read_csv(\"gfailruns_allevents_forAlex_v2.3.csv\") # Import CSV of Name, TLSE, Building level, Transportation Level, Utilities Level\n",
    "df = df.dropna(subset=['Buildings_Cost']) # Drop rows where DS is No Value for Buildings (should be same rows for Transportation and Utilities)\n",
    "df.drop(df[df['American?'] == 0].index, inplace=True) # Dropping non-American events\n",
    "\n",
    "# Minimum bin edge must be slightly less than 0 to account for TLSE=0\n",
    "# EDP_cut_bins = np.linspace(-100, 5200, num=54)\n",
    "EDP_cut_bins = xxx4\n",
    "\n",
    "#################################################################################\n",
    "# Create bins of TLSE labels and sort events into Bins\n",
    "EDP_cut_labels = np.linspace(0,len(EDP_cut_bins)-2,num=int(len(EDP_cut_bins)-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "following-bangkok",
   "metadata": {},
   "source": [
    "Below has four cost classes, not five"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "single-character",
   "metadata": {},
   "outputs": [],
   "source": [
    "spec = 1000000 # Number specified as rounded up to nearest log10 integer from max(HaggLQ)\n",
    "xxx = np.linspace(1,spec, num=spec) # Array of 1 to 10000, as integers\n",
    "xxx = np.log10(xxx) # Finds logs of above values, should be 1 to 4\n",
    "xxx2 = np.linspace(0,max(xxx),num=int(max(xxx)*3+1))\n",
    "xxx3=10**xxx2 # Creating actual bin bound values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "considerable-madison",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.33333333, 0.66666667, 1.        , 1.33333333,\n",
       "       1.66666667, 2.        , 2.33333333, 2.66666667, 3.        ,\n",
       "       3.33333333, 3.66666667, 4.        , 4.33333333, 4.66666667,\n",
       "       5.        , 5.33333333, 5.66666667, 6.        ])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xxx2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exterior-speech",
   "metadata": {},
   "outputs": [],
   "source": [
    "def part():\n",
    "#    FPs=[]\n",
    "\n",
    "    spec = 1000000 # Number specified as rounded up to nearest log10 integer from max(HaggLQ)\n",
    "    xxx = np.linspace(1,spec, num=spec) # Array of 1 to 10000, as integers\n",
    "    xxx = np.log10(xxx) # Finds logs of above values, should be 1 to 4\n",
    "    xxx2 = np.linspace(0,max(xxx),num=int(max(xxx)*3+1)) # Breaking up into x bins per log 10\n",
    "    xxx3=10**xxx2 # Creating actual bin bound values\n",
    "    xxx4 = xxx3.tolist()\n",
    "    xxx4[0] = xxx4[0]-1.01\n",
    "\n",
    "    # Create bins of damage level labels and sort events into Bins\n",
    "    damage_cut_labels = [0,1,2,3,4]\n",
    "    # Minimum bin edge must be slightly less than 0 to account for dollars damage =0\n",
    "    damage_cut_bins = [-0.1, 1000, 1000000, 10000000, 100000000, 1000000000]\n",
    "\n",
    "\n",
    "    df = pd.read_csv(\"gfailruns_allevents_forAlex_v2.3.csv\") # Import CSV of Name, TLSE, Building level, Transportation Level, Utilities Level\n",
    "    df = df.dropna(subset=['Buildings_Cost']) # Drop rows where DS is No Value for Buildings (should be same rows for Transportation and Utilities)\n",
    "    df.drop(df[df['American?'] == 0].index, inplace=True) # Dropping non-American events\n",
    "\n",
    "    # Minimum bin edge must be slightly less than 0 to account for TLSE=0\n",
    "    # EDP_cut_bins = np.linspace(-100, 5200, num=54)\n",
    "    EDP_cut_bins = xxx4\n",
    "\n",
    "    #################################################################################\n",
    "    # Create bins of TLSE labels and sort events into Bins\n",
    "    EDP_cut_labels = np.linspace(0,len(EDP_cut_bins)-2,num=int(len(EDP_cut_bins)-1))\n",
    "    # Creating column for which bin the TLSE falls into\n",
    "    df['TLSE_Bin'] = pd.cut(df['HaggLQ'], bins=EDP_cut_bins, labels=EDP_cut_labels)\n",
    "\n",
    "\n",
    "    # Calculating middle value for each bin\n",
    "    zipped_lists = zip(EDP_cut_bins[0:len(EDP_cut_bins)-1], EDP_cut_bins[1:len(EDP_cut_bins)])\n",
    "    Bin_Avg = [(x + y)/2 for (x, y) in zipped_lists]\n",
    "\n",
    "    # Making dataframe in which we can view damage level data\n",
    "    df2 = pd.DataFrame(zip(EDP_cut_bins[0:len(EDP_cut_bins)-1], EDP_cut_bins[1:len(EDP_cut_bins)],\n",
    "                                Bin_Avg[0:len(EDP_cut_bins)-1], EDP_cut_labels[0:len(EDP_cut_bins)-1]),\n",
    "                                columns=['Bin_Min', 'Bin_Max','Bin_Avg','Bin_Labels']) \n",
    "\n",
    "    # Counting number of analyses per bin\n",
    "    def count_(bin_type,bin_lev):\n",
    "        subset_df = df[bin_type == bin_lev]\n",
    "        return subset_df.TLSE_Bin.count()\n",
    "\n",
    "    y=[]\n",
    "    # Need to have a +1 because of the way range() counts upwards, it stops 1 short of upper limit\n",
    "    # For all labels, count the number of analyses in that level\n",
    "    for i in range(0,len(EDP_cut_labels)):\n",
    "        y.append(count_(df.TLSE_Bin,i)) \n",
    "\n",
    "    # Appending this column to dataframe or recreate dataframe with it included\n",
    "    df2['Num_Analyses']=y\n",
    "\n",
    "    df2.drop(df2[df2['Num_Analyses'] == 0].index, inplace=True) # Dropping bins with 0 events\n",
    "    df2 = df2.reset_index(drop=True) # resetting index to start at 0\n",
    "\n",
    "    def damagelevel(infrastructure):\n",
    "        df[str(infrastructure)+'_CostBin'] = pd.cut(df[str(infrastructure)+'_Cost'], bins=damage_cut_bins, labels=damage_cut_labels)\n",
    "        df.head(20)\n",
    "\n",
    "    damagelevel('Buildings')\n",
    "    damagelevel('Transportation')\n",
    "    damagelevel('Utilities')\n",
    "    damagelevel('Total')\n",
    "\n",
    "    # Probably going to change the below line to fit new DSs\n",
    "    d = [df[\"Buildings_Cost\"].max(), df[\"Transportation_Cost\"].max(), df[\"Utilities_Cost\"].min()]\n",
    "    DS_max = len(damage_cut_labels)\n",
    "\n",
    "    # Counts the number of events over a specified damage level for each TLSE bin\n",
    "    def count_(bin_type, T_bin_lev, Dam_bin_lev):\n",
    "        # select only rows where the TLSE bin is equal to bin i\n",
    "        subset_df=df[df.TLSE_Bin == T_bin_lev]\n",
    "        # select only rows where the buildings/transportation/utilities level is >= level j\n",
    "        subset_df=subset_df[bin_type >= Dam_bin_lev]\n",
    "        return subset_df.TLSE_Bin.count()\n",
    "\n",
    "    # Appends number exceeding DS to arrays in correct order\n",
    "    # For the range of all damage states, need +1 because of way range counts upwards\n",
    "    for j in range(0,len(damage_cut_labels)):\n",
    "        # Creating empty arrays \n",
    "        y1=[]\n",
    "        y2=[]\n",
    "        y3=[]\n",
    "        y4=[]\n",
    "\n",
    "        # For each EDP Bin\n",
    "        for i in range(0,len(df2)): \n",
    "            # count the number of analyses of damage state \"j\", for bin label in row \"i\" of df2\n",
    "            # Uses the function \"count_\" created a few blocks up\n",
    "            y1.append(count_(df.Buildings_CostBin, df2.iloc[i,3], j))        \n",
    "            y2.append(count_(df.Transportation_CostBin, df2.iloc[i,3], j))\n",
    "            y3.append(count_(df.Utilities_CostBin, df2.iloc[i,3], j))\n",
    "            y4.append(count_(df.Total_CostBin, df2.iloc[i,3],j))\n",
    "        df3 = pd.DataFrame(y1)\n",
    "        # CDS instead of DS represents \"Cost Damage States\"\n",
    "        # \"Observed\" refers to proportion of total analyses for that bin reaching specified CDS\n",
    "        df2['Buildings_CDS_'+str(j)] = df3\n",
    "        df2['Buildings_CDS_'+str(j)+'_Observed'] = df2['Buildings_CDS_'+str(j)]/df2['Num_Analyses']\n",
    "        df3 = pd.DataFrame(y2)\n",
    "        df2['Transportation_CDS_'+str(j)] = df3\n",
    "        df2['Transportation_CDS_'+str(j)+'_Observed'] = df2['Transportation_CDS_'+str(j)]/df2['Num_Analyses']\n",
    "        df3 = pd.DataFrame(y3)\n",
    "        df2['Utilities_CDS_'+str(j)] = df3\n",
    "        df2['Utilities_CDS_'+str(j)+'_Observed'] = df2['Utilities_CDS_'+str(j)]/df2['Num_Analyses']\n",
    "        df3 = pd.DataFrame(y4)\n",
    "        df2['Total_CDS_'+str(j)] = df3\n",
    "        df2['Total_CDS_'+str(j)+'_Observed'] = df2['Total_CDS_'+str(j)]/df2['Num_Analyses']\n",
    "\n",
    "    df5 = df2.drop(['Buildings_CDS_0', 'Buildings_CDS_0_Observed', 'Transportation_CDS_0', \n",
    "                    'Transportation_CDS_0_Observed', 'Utilities_CDS_0', \n",
    "                    'Utilities_CDS_0_Observed'], axis=1) # Drop these columns\n",
    "\n",
    "    # df4 represents creating x values of fragility curve itself\n",
    "    # Must start at 1 instead of 0 because log(0) does not exist\n",
    "    xx = np.linspace(1, max(df['HaggLQ']), num=int(max(df['HaggLQ'])))\n",
    "    df4 = pd.DataFrame(xx,columns=['Aggregate Liquefaction Hazard'])\n",
    "    aa = df4.iloc[:,0]\n",
    "\n",
    "    def g_2(category):\n",
    "        # Plotting fragility functions with observed points\n",
    "        mpl.style.use('default')\n",
    "        fig, ax = plt.subplots(figsize=(6, 4.5))\n",
    "        csfont = {'fontname':'Times New Roman'}\n",
    "        ax.set_xscale('log')\n",
    "        \n",
    "        for DS in range(1,len(damage_cut_labels)):\n",
    "          # This is where we need to have definition of loop start    \n",
    "            a1 = df2.iloc[:,4] # Num events in each bin\n",
    "            a2 = df2[str(category)+'_CDS_'+str(DS)] # Num exceedances (Building level 1) in each bin\n",
    "            a3 = df2.iloc[:,2] # Avg bin TLSE values\n",
    "\n",
    "            a1 = a1.values.tolist()\n",
    "            a2 = a2.values.tolist()\n",
    "            a3 = a3.values.tolist()\n",
    "\n",
    "            # Define function to be maximum using Automation\n",
    "            def f(params):\n",
    "                theta, beta = params\n",
    "                bounds = ((0,None),(0,None))\n",
    "                # CDF finds the probability of exceeding damage state\n",
    "                # PMF is the likelihood of achieving the CDF value given the number of events in each bin and exceedances of damage state\n",
    "                # Get product of likelihoods\n",
    "                # Use -1 to get maximum insted of minimum\n",
    "                c = []\n",
    "                d = []\n",
    "                for i in range(0,len(df2)):\n",
    "                    c.append(stats.binom.pmf(a2[i], a1[i], stats.norm.cdf(math.log(a3[i]), loc=math.log(theta),scale=beta)))  \n",
    "                return -1*np.product([c])\n",
    "\n",
    "            # Minimize the defined function using starting theta and beta\n",
    "            # Some reason this is coming out with parameters near the input only instead of actual results\n",
    "            res = minimize(f,[100,10],method='Nelder-Mead',options={'maxiter': 10000})\n",
    "\n",
    "            if res.success:\n",
    "                fitted_params = res.x\n",
    "                print(fitted_params)\n",
    "            else:\n",
    "                raise ValueError(res.message)\n",
    "\n",
    "            # Creating fitted fragility points from fitted parameters for the curve\n",
    "            yy=[]\n",
    "            for i in range(0,len(df4)):\n",
    "                yy.append(stats.norm.cdf(math.log(aa[i]),loc=math.log(fitted_params[0]),scale=fitted_params[1]))\n",
    "            ######################################################################  \n",
    "            df4['Fitted_Values_CDS_'+str(DS)]=yy # Adding column to dataframe\n",
    "            \n",
    "        \n",
    "            # THE ABOVE ALSO CONTAINS RELATIONSHIPS \n",
    "        ######################################################################   \n",
    "\n",
    "            #ax.plot('Aggregate Liquefaction Hazard', 'Fitted_Values_CDS_'+str(DS), 'k-', label=str(category)+' '+str(DS)+' Fitted',data=df4)\n",
    "            #ax.plot('Bin_Avg', str(category)+'_CDS_'+str(DS)+'_Observed','k+', markersize=16,\n",
    "                    #label=str(category)+' '+str(DS)+' Observed',data=df5)\n",
    "\n",
    "            #print(df4['Fitted_Values_CDS_1'])\n",
    "        \n",
    "        ax.plot('Aggregate Liquefaction Hazard', 'Fitted_Values_CDS_1', 'k-', label=str(category)+' 1'+' Fitted',data=df4)\n",
    "        ax.plot('Bin_Avg', str(category)+'_CDS_1'+'_Observed','kd', markersize=10, markerfacecolor='none',\n",
    "                label=str(category)+' 1'+' Observed',data=df5)\n",
    "\n",
    "#         ax.plot('Aggregate Liquefaction Hazard', 'Fitted_Values_CDS_2', 'k--', label=str(category)+' 2'+' Fitted',data=df4)\n",
    "#         ax.plot('Bin_Avg', str(category)+'_CDS_2'+'_Observed','k+', mfc='none', markersize=16,\n",
    "#                label=str(category)+' 2'+' Observed',data=df5) # DS_1 observed\n",
    "\n",
    "#         ax.plot('Aggregate Liquefaction Hazard', 'Fitted_Values_CDS_3', 'k-.', label=str(category)+' 3'+' Fitted',data=df4)\n",
    "#         ax.plot('Bin_Avg', str(category)+'_CDS_3'+'_Observed','ko', markersize=10, markerfacecolor='none',\n",
    "#                 label=str(category)+' 3'+' Observed',data=df5)\n",
    "\n",
    "#         ax.plot('Aggregate Liquefaction Hazard', 'Fitted_Values_CDS_4', 'k:', label=str(category)+' 4'+' Fitted',data=df4)\n",
    "#         ax.plot('Bin_Avg', str(category)+'_CDS_4'+'_Observed','k*', mfc='none', markersize=10,\n",
    "#                label=str(category)+' 4'+' Observed',data=df5) # DS_1 observed\n",
    "\n",
    "#         ax.plot('Aggregate Liquefaction Hazard', 'Fitted_Values_CDS_5', 'k:', label=str(category)+' 5'+' Fitted',data=df4)\n",
    "#         ax.plot('Bin_Avg', str(category)+'_CDS_5'+'_Observed','k*', mfc='none', markersize=10,\n",
    "#                label=str(category)+' 5'+' Observed',data=df5) # DS_1 observed\n",
    "\n",
    "        plt.xlabel('Aggregate Liquefaction Hazard Bin Average', fontsize=10,**csfont)\n",
    "        plt.ylabel('Probability of Exceeding Damage State Thresholds', fontsize=10,**csfont)\n",
    "        plt.legend(loc='upper left', fontsize='8')\n",
    "\n",
    "        fmt = '{x:,.0f}'\n",
    "        tick = mtick.StrMethodFormatter(fmt)\n",
    "        ax.xaxis.set_major_formatter(tick)\n",
    "        plt.xticks([1,10,100,1000],**csfont)\n",
    "            # For ticks, need max to be one unit higher than the value I actually want\n",
    "        plt.ylim(-0.05, 1.05)\n",
    "        plt.yticks(np.arange(0, 1.2, 0.2),**csfont)\n",
    "        plt.grid(linestyle='-', linewidth='0.5')\n",
    "        plt.savefig('KCC_HtotCostFxns_1Levs_'+str(category)+'.png',format=\"PNG\",dpi=500,bbox_inches=\"tight\")\n",
    "   # g_2('Buildings')\n",
    "   # g_2('Transportation')\n",
    "   # g_2('Utilities')\n",
    "    g_2('Total')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "finnish-monte",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "part()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "compact-writer",
   "metadata": {},
   "source": [
    "# Attempting to substitute PopExp or TLSE values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "decreased-memory",
   "metadata": {},
   "outputs": [],
   "source": [
    "excitation_type = Htot\n",
    "if excitation_type==Htot:\n",
    "    excit_bin='TLSE_Bin'\n",
    "    agg_hazard='HaggLQ'\n",
    "    x_label='Aggregate Liquefaction Hazard'\n",
    "elif excitation_type==PopExp:\n",
    "    excit_bin='Pop_Bin'\n",
    "    agg_hazard='ExpPopLQ'\n",
    "    x_label='Population Exposure'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "solar-following",
   "metadata": {},
   "outputs": [],
   "source": [
    "excitation_type='Pop'\n",
    "excit_bin='Pop_Bin'\n",
    "agg_hazard='ExpPopLQ'\n",
    "x_label='Population Exposure'\n",
    "# Not quite sure how to integrate inputs into df.colunn_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "micro-mexico",
   "metadata": {},
   "outputs": [],
   "source": [
    "def part_pop():\n",
    "#    FPs=[]\n",
    "\n",
    "    spec = 1000000 # Number specified as rounded up to nearest log10 integer from max(HaggLQ)\n",
    "    xxx = np.linspace(1,spec, num=spec) # Array of 1 to 10000, as integers\n",
    "    xxx = np.log10(xxx) # Finds logs of above values, should be 1 to 4\n",
    "    xxx2 = np.linspace(0,max(xxx),num=int(max(xxx)*3+1)) # Breaking up into x bins per log 10\n",
    "    xxx3=10**xxx2 # Creating actual bin bound values\n",
    "    xxx4 = xxx3.tolist()\n",
    "    xxx4[0] = xxx4[0]-1.01\n",
    "\n",
    "    # Create bins of damage level labels and sort events into Bins\n",
    "    damage_cut_labels = [0,1,2,3,4]\n",
    "    # Minimum bin edge must be slightly less than 0 to account for dollars damage =0\n",
    "    damage_cut_bins = [-0.1, 1000, 1000000, 10000000, 100000000, 1000000000]\n",
    "\n",
    "\n",
    "    df = pd.read_csv(\"gfailruns_allevents_forAlex_v2.3.csv\") # Import CSV of Name, TLSE, Building level, Transportation Level, Utilities Level\n",
    "    df = df.dropna(subset=['Buildings_Cost']) # Drop rows where DS is No Value for Buildings (should be same rows for Transportation and Utilities)\n",
    "    df.drop(df[df['American?'] == 0].index, inplace=True) # Dropping non-American events\n",
    "\n",
    "    # Minimum bin edge must be slightly less than 0 to account for TLSE=0\n",
    "    # EDP_cut_bins = np.linspace(-100, 5200, num=54)\n",
    "    EDP_cut_bins = xxx4\n",
    "\n",
    "    #################################################################################\n",
    "    # Create bins of TLSE labels and sort events into Bins\n",
    "    EDP_cut_labels = np.linspace(0,len(EDP_cut_bins)-2,num=int(len(EDP_cut_bins)-1))\n",
    "    # Creating column for which bin the TLSE falls into\n",
    "    df[excit_bin] = pd.cut(df[agg_hazard], bins=EDP_cut_bins, labels=EDP_cut_labels)\n",
    "\n",
    "\n",
    "    # Calculating middle value for each bin\n",
    "    zipped_lists = zip(EDP_cut_bins[0:len(EDP_cut_bins)-1], EDP_cut_bins[1:len(EDP_cut_bins)])\n",
    "    Bin_Avg = [(x + y)/2 for (x, y) in zipped_lists]\n",
    "\n",
    "    # Making dataframe in which we can view damage level data\n",
    "    df2 = pd.DataFrame(zip(EDP_cut_bins[0:len(EDP_cut_bins)-1], EDP_cut_bins[1:len(EDP_cut_bins)],\n",
    "                                Bin_Avg[0:len(EDP_cut_bins)-1], EDP_cut_labels[0:len(EDP_cut_bins)-1]),\n",
    "                                columns=['Bin_Min', 'Bin_Max','Bin_Avg','Bin_Labels']) \n",
    "\n",
    "    # Counting number of analyses per bin\n",
    "    def count_(bin_type,bin_lev):\n",
    "        subset_df = df[bin_type == bin_lev]\n",
    "        return subset_df.Pop_Bin.count()\n",
    "\n",
    "    y=[]\n",
    "    # Need to have a +1 because of the way range() counts upwards, it stops 1 short of upper limit\n",
    "    # For all labels, count the number of analyses in that level\n",
    "    for i in range(0,len(EDP_cut_labels)):\n",
    "        y.append(count_(df.Pop_Bin,i)) \n",
    "\n",
    "    # Appending this column to dataframe or recreate dataframe with it included\n",
    "    df2['Num_Analyses']=y\n",
    "\n",
    "    df2.drop(df2[df2['Num_Analyses'] == 0].index, inplace=True) # Dropping bins with 0 events\n",
    "    df2 = df2.reset_index(drop=True) # resetting index to start at 0\n",
    "\n",
    "    def damagelevel(infrastructure):\n",
    "        df[str(infrastructure)+'_CostBin'] = pd.cut(df[str(infrastructure)+'_Cost'], bins=damage_cut_bins, labels=damage_cut_labels)\n",
    "        df.head(20)\n",
    "\n",
    "    damagelevel('Buildings')\n",
    "    damagelevel('Transportation')\n",
    "    damagelevel('Utilities')\n",
    "    damagelevel('Total')\n",
    "\n",
    "    # Probably going to change the below line to fit new DSs\n",
    "    d = [df[\"Buildings_Cost\"].max(), df[\"Transportation_Cost\"].max(), df[\"Utilities_Cost\"].min()]\n",
    "    DS_max = len(damage_cut_labels)\n",
    "\n",
    "    # Counts the number of events over a specified damage level for each TLSE bin\n",
    "    def count_(bin_type, T_bin_lev, Dam_bin_lev):\n",
    "        # select only rows where the TLSE bin is equal to bin i\n",
    "        subset_df=df[df.Pop_Bin == T_bin_lev]\n",
    "        # select only rows where the buildings/transportation/utilities level is >= level j\n",
    "        subset_df=subset_df[bin_type >= Dam_bin_lev]\n",
    "        return subset_df.Pop_Bin.count()\n",
    "\n",
    "    # Appends number exceeding DS to arrays in correct order\n",
    "    # For the range of all damage states, need +1 because of way range counts upwards\n",
    "    for j in range(0,len(damage_cut_labels)):\n",
    "        # Creating empty arrays \n",
    "        y1=[]\n",
    "        y2=[]\n",
    "        y3=[]\n",
    "        y4=[]\n",
    "\n",
    "        # For each EDP Bin\n",
    "        for i in range(0,len(df2)): \n",
    "            # count the number of analyses of damage state \"j\", for bin label in row \"i\" of df2\n",
    "            # Uses the function \"count_\" created a few blocks up\n",
    "            y1.append(count_(df.Buildings_CostBin, df2.iloc[i,3], j))        \n",
    "            y2.append(count_(df.Transportation_CostBin, df2.iloc[i,3], j))\n",
    "            y3.append(count_(df.Utilities_CostBin, df2.iloc[i,3], j))\n",
    "            y4.append(count_(df.Total_CostBin, df2.iloc[i,3],j))\n",
    "        df3 = pd.DataFrame(y1)\n",
    "        # CDS instead of DS represents \"Cost Damage States\"\n",
    "        # \"Observed\" refers to proportion of total analyses for that bin reaching specified CDS\n",
    "        df2['Buildings_CDS_'+str(j)] = df3\n",
    "        df2['Buildings_CDS_'+str(j)+'_Observed'] = df2['Buildings_CDS_'+str(j)]/df2['Num_Analyses']\n",
    "        df3 = pd.DataFrame(y2)\n",
    "        df2['Transportation_CDS_'+str(j)] = df3\n",
    "        df2['Transportation_CDS_'+str(j)+'_Observed'] = df2['Transportation_CDS_'+str(j)]/df2['Num_Analyses']\n",
    "        df3 = pd.DataFrame(y3)\n",
    "        df2['Utilities_CDS_'+str(j)] = df3\n",
    "        df2['Utilities_CDS_'+str(j)+'_Observed'] = df2['Utilities_CDS_'+str(j)]/df2['Num_Analyses']\n",
    "        df3 = pd.DataFrame(y4)\n",
    "        df2['Total_CDS_'+str(j)] = df3\n",
    "        df2['Total_CDS_'+str(j)+'_Observed'] = df2['Total_CDS_'+str(j)]/df2['Num_Analyses']\n",
    "\n",
    "    df5 = df2.drop(['Buildings_CDS_0', 'Buildings_CDS_0_Observed', 'Transportation_CDS_0', \n",
    "                    'Transportation_CDS_0_Observed', 'Utilities_CDS_0', \n",
    "                    'Utilities_CDS_0_Observed'], axis=1) # Drop these columns\n",
    "\n",
    "    # df4 represents creating x values of fragility curve itself\n",
    "    # Must start at 1 instead of 0 because log(0) does not exist\n",
    "    xx = np.linspace(1, max(df[agg_hazard]), num=int(max(df[agg_hazard])))\n",
    "    df4 = pd.DataFrame(xx,columns=[x_label])\n",
    "    aa = df4.iloc[:,0]\n",
    "\n",
    "    def g_2(category):\n",
    "        # Plotting fragility functions with observed points\n",
    "        mpl.style.use('default')\n",
    "        fig, ax = plt.subplots(figsize=(6, 4.5))\n",
    "        csfont = {'fontname':'Times New Roman'}\n",
    "        ax.set_xscale('log')\n",
    "        \n",
    "        for DS in range(1,len(damage_cut_labels)):\n",
    "          # This is where we need to have definition of loop start    \n",
    "            a1 = df2.iloc[:,4] # Num events in each bin\n",
    "            a2 = df2[str(category)+'_CDS_'+str(DS)] # Num exceedances (Building level 1) in each bin\n",
    "            a3 = df2.iloc[:,2] # Avg bin TLSE values\n",
    "\n",
    "            a1 = a1.values.tolist()\n",
    "            a2 = a2.values.tolist()\n",
    "            a3 = a3.values.tolist()\n",
    "\n",
    "            # Define function to be maximum using Automation\n",
    "            def f(params):\n",
    "                theta, beta = params\n",
    "                bounds = ((0,None),(0,None))\n",
    "                # CDF finds the probability of exceeding damage state\n",
    "                # PMF is the likelihood of achieving the CDF value given the number of events in each bin and exceedances of damage state\n",
    "                # Get product of likelihoods\n",
    "                # Use -1 to get maximum insted of minimum\n",
    "                c = []\n",
    "                d = []\n",
    "                for i in range(0,len(df2)):\n",
    "                    c.append(stats.binom.pmf(a2[i], a1[i], stats.norm.cdf(math.log(a3[i]), loc=math.log(theta),scale=beta)))  \n",
    "                return -1*np.product([c])\n",
    "\n",
    "            # Minimize the defined function using starting theta and beta\n",
    "            # Some reason this is coming out with parameters near the input only instead of actual results\n",
    "            res = minimize(f,[100,10],method='Nelder-Mead',options={'maxiter': 10000})\n",
    "\n",
    "            if res.success:\n",
    "                fitted_params = res.x\n",
    "                print(fitted_params)\n",
    "            else:\n",
    "                raise ValueError(res.message)\n",
    "\n",
    "            # Creating fitted fragility points from fitted parameters for the curve\n",
    "            yy=[]\n",
    "            for i in range(0,len(df4)):\n",
    "                yy.append(stats.norm.cdf(math.log(aa[i]),loc=math.log(fitted_params[0]),scale=fitted_params[1]))\n",
    "            ######################################################################  \n",
    "            df4['Fitted_Values_CDS_'+str(DS)]=yy # Adding column to dataframe\n",
    "            \n",
    "        \n",
    "            # THE ABOVE ALSO CONTAINS RELATIONSHIPS \n",
    "        ######################################################################   \n",
    "\n",
    "            #ax.plot('Aggregate Liquefaction Hazard', 'Fitted_Values_CDS_'+str(DS), 'k-', label=str(category)+' '+str(DS)+' Fitted',data=df4)\n",
    "            #ax.plot('Bin_Avg', str(category)+'_CDS_'+str(DS)+'_Observed','k+', markersize=16,\n",
    "                    #label=str(category)+' '+str(DS)+' Observed',data=df5)\n",
    "\n",
    "            #print(df4['Fitted_Values_CDS_1'])\n",
    "        \n",
    "        ax.plot(x_label, 'Fitted_Values_CDS_1', 'k-', label=str(category)+' 1'+' Fitted',data=df4)\n",
    "        ax.plot('Bin_Avg', str(category)+'_CDS_1'+'_Observed','kd', markersize=10, markerfacecolor='none',\n",
    "                label=str(category)+' 1'+' Observed',data=df5)\n",
    "\n",
    "        ax.plot(x_label, 'Fitted_Values_CDS_2', 'k--', label=str(category)+' 2'+' Fitted',data=df4)\n",
    "        ax.plot('Bin_Avg', str(category)+'_CDS_2'+'_Observed','k+', mfc='none', markersize=16,\n",
    "               label=str(category)+' 2'+' Observed',data=df5) # DS_1 observed\n",
    "\n",
    "        ax.plot(x_label, 'Fitted_Values_CDS_3', 'k-.', label=str(category)+' 3'+' Fitted',data=df4)\n",
    "        ax.plot('Bin_Avg', str(category)+'_CDS_3'+'_Observed','ko', markersize=10, markerfacecolor='none',\n",
    "                label=str(category)+' 3'+' Observed',data=df5)\n",
    "\n",
    "        ax.plot(x_label, 'Fitted_Values_CDS_4', 'k:', label=str(category)+' 4'+' Fitted',data=df4)\n",
    "        ax.plot('Bin_Avg', str(category)+'_CDS_4'+'_Observed','k*', mfc='none', markersize=10,\n",
    "               label=str(category)+' 4'+' Observed',data=df5) # DS_1 observed\n",
    "\n",
    "#         ax.plot('Aggregate Liquefaction Hazard', 'Fitted_Values_CDS_5', 'k:', label=str(category)+' 5'+' Fitted',data=df4)\n",
    "#         ax.plot('Bin_Avg', str(category)+'_CDS_5'+'_Observed','k*', mfc='none', markersize=10,\n",
    "#                label=str(category)+' 5'+' Observed',data=df5) # DS_1 observed\n",
    "\n",
    "        plt.xlabel(x_label, fontsize=10,**csfont)\n",
    "        plt.ylabel('Probability of Exceeding Damage State Thresholds', fontsize=10,**csfont)\n",
    "        plt.legend(loc='upper left', fontsize='8')\n",
    "\n",
    "        fmt = '{x:,.0f}'\n",
    "        tick = mtick.StrMethodFormatter(fmt)\n",
    "        ax.xaxis.set_major_formatter(tick)\n",
    "        plt.xticks([1,10,100,1000,10000,100000],**csfont)\n",
    "            # For ticks, need max to be one unit higher than the value I actually want\n",
    "        plt.ylim(-0.05, 1.05)\n",
    "        plt.yticks(np.arange(0, 1.2, 0.2),**csfont)\n",
    "        plt.grid(linestyle='-', linewidth='0.5')\n",
    "        plt.savefig('KCC_HtotCostFxns_4Levs_'+str(category)+'.png',format=\"PNG\",dpi=500,bbox_inches=\"tight\")\n",
    "    g_2('Buildings')\n",
    "    g_2('Transportation')\n",
    "    g_2('Utilities')\n",
    "    g_2('Total')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "certified-capitol",
   "metadata": {},
   "outputs": [],
   "source": [
    "part_pop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "immediate-deadline",
   "metadata": {},
   "source": [
    "# Section below: adding excitation measure input to use in calculation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adjusted-intake",
   "metadata": {},
   "source": [
    "Changes made between part() and part_2()\n",
    "1. Drop HaggLQ, use the input df as new column added in same place with same name\n",
    "2. Commented out plots from appearing\n",
    "3. Changed spec to spec = a million\n",
    "4. Record fitted_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eligible-robert",
   "metadata": {},
   "outputs": [],
   "source": [
    "FPs_med=[]\n",
    "FPs_disp=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alpha-sarah",
   "metadata": {},
   "outputs": [],
   "source": [
    "def part_2(df,iii):\n",
    "    spec = 1000000 # Number specified as rounded up to nearest log10 integer from max(HaggLQ)\n",
    "    xxx = np.linspace(1,spec, num=spec) # Array of 1 to 10000, as integers\n",
    "    xxx = np.log10(xxx) # Finds logs of above values, should be 1 to 4\n",
    "    xxx2 = np.linspace(0,max(xxx),num=int(max(xxx)*3+1)) # Breaking up into 2 bins per log 10\n",
    "    xxx3=10**xxx2 # Creating actual bin bound values\n",
    "    xxx4 = xxx3.tolist()\n",
    "    xxx4[0] = xxx4[0]-1.01\n",
    "\n",
    "    # Create bins of damage level labels and sort events into Bins\n",
    "    damage_cut_labels = [0,1,2,3,4,5]\n",
    "    # Minimum bin edge must be slightly less than 0 to account for dollars damage =0\n",
    "    damage_cut_bins = [-0.1, 1000, 100000, 1000000, 10000000, 100000000, 1000000000]\n",
    "\n",
    "#     df = pd.read_csv(\"gfailruns_allevents_forAlex_v2.3.csv\") # Import CSV of Name, TLSE, Building level, Transportation Level, Utilities Level\n",
    "#     df = df.dropna(subset=['Buildings_Cost']) # Drop rows where DS is No Value for Buildings (should be same rows for Transportation and Utilities)\n",
    "#     df.drop(df[df['American?'] == 0].index, inplace=True) # Dropping non-American events\n",
    "\n",
    "    # Minimum bin edge must be slightly less than 0 to account for TLSE=0\n",
    "    # EDP_cut_bins = np.linspace(-100, 5200, num=54)\n",
    "    EDP_cut_bins = xxx4\n",
    "\n",
    "    #################################################################################\n",
    "    # Create bins of TLSE labels and sort events into Bins\n",
    "    EDP_cut_labels = np.linspace(0,len(EDP_cut_bins)-2,num=int(len(EDP_cut_bins)-1))\n",
    "    # Creating column for which bin the TLSE falls into\n",
    "    df['TLSE_Bin'] = pd.cut(df['HaggLQ'], bins=EDP_cut_bins, labels=EDP_cut_labels)\n",
    "\n",
    "\n",
    "    # Calculating middle value for each bin\n",
    "    zipped_lists = zip(EDP_cut_bins[0:len(EDP_cut_bins)-1], EDP_cut_bins[1:len(EDP_cut_bins)])\n",
    "    Bin_Avg = [(x + y)/2 for (x, y) in zipped_lists]\n",
    "\n",
    "    # Making dataframe in which we can view damage level data\n",
    "    df2 = pd.DataFrame(zip(EDP_cut_bins[0:len(EDP_cut_bins)-1], EDP_cut_bins[1:len(EDP_cut_bins)],\n",
    "                                Bin_Avg[0:len(EDP_cut_bins)-1], EDP_cut_labels[0:len(EDP_cut_bins)-1]),\n",
    "                                columns=['Bin_Min', 'Bin_Max','Bin_Avg','Bin_Labels']) \n",
    "\n",
    "    # Counting number of analyses per bin\n",
    "    def count_(bin_type,bin_lev):\n",
    "        subset_df = df[bin_type == bin_lev]\n",
    "        return subset_df.TLSE_Bin.count()\n",
    "\n",
    "    y=[]\n",
    "    # Need to have a +1 because of the way range() counts upwards, it stops 1 short of upper limit\n",
    "    # For all labels, count the number of analyses in that level\n",
    "    for i in range(0,len(EDP_cut_labels)):\n",
    "        y.append(count_(df.TLSE_Bin,i)) \n",
    "\n",
    "    # Appending this column to dataframe or recreate dataframe with it included\n",
    "    df2['Num_Analyses']=y\n",
    "\n",
    "    df2.drop(df2[df2['Num_Analyses'] == 0].index, inplace=True) # Dropping bins with 0 events\n",
    "    df2 = df2.reset_index(drop=True) # resetting index to start at 0\n",
    "\n",
    "    def damagelevel(infrastructure):\n",
    "        df[str(infrastructure)+'_CostBin'] = pd.cut(df[str(infrastructure)+'_Cost'], bins=damage_cut_bins, labels=damage_cut_labels)\n",
    "        df.head(20)\n",
    "\n",
    "    damagelevel('Buildings')\n",
    "    damagelevel('Transportation')\n",
    "    damagelevel('Utilities')\n",
    "    damagelevel('Total')\n",
    "\n",
    "    # Probably going to change the below line to fit new DSs\n",
    "    d = [df[\"Buildings_Cost\"].max(), df[\"Transportation_Cost\"].max(), df[\"Utilities_Cost\"].min()]\n",
    "    DS_max = len(damage_cut_labels)\n",
    "\n",
    "    # Counts the number of events over a specified damage level for each TLSE bin\n",
    "    def count_(bin_type, T_bin_lev, Dam_bin_lev):\n",
    "        # select only rows where the TLSE bin is equal to bin i\n",
    "        subset_df=df[df.TLSE_Bin == T_bin_lev]\n",
    "        # select only rows where the buildings/transportation/utilities level is >= level j\n",
    "        subset_df=subset_df[bin_type >= Dam_bin_lev]\n",
    "        return subset_df.TLSE_Bin.count()\n",
    "\n",
    "    # Appends number exceeding DS to arrays in correct order\n",
    "    # For the range of all damage states, need +1 because of way range counts upwards\n",
    "    for j in range(0,len(damage_cut_labels)):\n",
    "        # Creating empty arrays \n",
    "        y1=[]\n",
    "        y2=[]\n",
    "        y3=[]\n",
    "        y4=[]\n",
    "\n",
    "        # For each EDP Bin\n",
    "        for i in range(0,len(df2)): \n",
    "            # count the number of analyses of damage state \"j\", for bin label in row \"i\" of df2\n",
    "            # Uses the function \"count_\" created a few blocks up\n",
    "            y1.append(count_(df.Buildings_CostBin, df2.iloc[i,3], j))        \n",
    "            y2.append(count_(df.Transportation_CostBin, df2.iloc[i,3], j))\n",
    "            y3.append(count_(df.Utilities_CostBin, df2.iloc[i,3], j))\n",
    "            y4.append(count_(df.Total_CostBin, df2.iloc[i,3],j))\n",
    "        df3 = pd.DataFrame(y1)\n",
    "        # CDS instead of DS represents \"Cost Damage States\"\n",
    "        # \"Observed\" refers to proportion of total analyses for that bin reaching specified CDS\n",
    "        df2['Buildings_CDS_'+str(j)] = df3\n",
    "        df2['Buildings_CDS_'+str(j)+'_Observed'] = df2['Buildings_CDS_'+str(j)]/df2['Num_Analyses']\n",
    "        df3 = pd.DataFrame(y2)\n",
    "        df2['Transportation_CDS_'+str(j)] = df3\n",
    "        df2['Transportation_CDS_'+str(j)+'_Observed'] = df2['Transportation_CDS_'+str(j)]/df2['Num_Analyses']\n",
    "        df3 = pd.DataFrame(y3)\n",
    "        df2['Utilities_CDS_'+str(j)] = df3\n",
    "        df2['Utilities_CDS_'+str(j)+'_Observed'] = df2['Utilities_CDS_'+str(j)]/df2['Num_Analyses']\n",
    "        df3 = pd.DataFrame(y4)\n",
    "        df2['Total_CDS_'+str(j)] = df3\n",
    "        df2['Total_CDS_'+str(j)+'_Observed'] = df2['Total_CDS_'+str(j)]/df2['Num_Analyses']\n",
    "\n",
    "    df5 = df2.drop(['Buildings_CDS_0', 'Buildings_CDS_0_Observed', 'Transportation_CDS_0', \n",
    "                    'Transportation_CDS_0_Observed', 'Utilities_CDS_0', \n",
    "                    'Utilities_CDS_0_Observed'], axis=1) # Drop these columns\n",
    "\n",
    "    # df4 represents creating x values of fragility curve itself\n",
    "    # Must start at 1 instead of 0 because log(0) does not exist\n",
    "    xx = np.linspace(1, max(df['HaggLQ']), num=int(max(df['HaggLQ'])))\n",
    "    df4 = pd.DataFrame(xx,columns=['Aggregate Liquefaction Hazard'])\n",
    "    aa = df4.iloc[:,0]\n",
    "    \n",
    "    def g_2(category):\n",
    "        global FPs_med\n",
    "        global FPs_disp\n",
    "        FPs_med=[]\n",
    "        FPs_disp=[]\n",
    "        # Plotting fragility functions with observed points\n",
    "#         mpl.style.use('default')\n",
    "#         fig, ax = plt.subplots(figsize=(6, 4.5))\n",
    "#         csfont = {'fontname':'Times New Roman'}\n",
    "#         ax.set_xscale('log')\n",
    "\n",
    "        for DS in range(1,len(damage_cut_labels)):\n",
    "          # This is where we need to have definition of loop start    \n",
    "            a1 = df2.iloc[:,4] # Num events in each bin\n",
    "            a2 = df2[str(category)+'_CDS_'+str(DS)] # Num exceedances (Building level 1) in each bin\n",
    "            a3 = df2.iloc[:,2] # Avg bin TLSE values\n",
    "\n",
    "            a1 = a1.values.tolist()\n",
    "            a2 = a2.values.tolist()\n",
    "            a3 = a3.values.tolist()\n",
    "\n",
    "            # Define function to be maximum using Automation\n",
    "            def f(params):\n",
    "                theta, beta = params\n",
    "                bounds = ((0,None),(0,None))\n",
    "                # CDF finds the probability of exceeding damage state\n",
    "                # PMF is the likelihood of achieving the CDF value given the number of events in each bin and exceedances of damage state\n",
    "                # Get product of likelihoods\n",
    "                # Use -1 to get maximum insted of minimum\n",
    "                c = []\n",
    "                d = []\n",
    "                for i in range(0,len(df2)):\n",
    "                    c.append(stats.binom.pmf(a2[i], a1[i], stats.norm.cdf(math.log(a3[i]), loc=math.log(theta),scale=beta)))  \n",
    "                return -1*np.product([c])\n",
    "\n",
    "            # Minimize the defined function using starting theta and beta\n",
    "            # Some reason this is coming out with parameters near the input only instead of actual results\n",
    "            res = minimize(f,[100,10],method='Nelder-Mead',options={'maxiter': 10000})\n",
    "\n",
    "            if res.success:\n",
    "                fitted_params = res.x\n",
    "                #print(fitted_params)\n",
    "            else:\n",
    "                raise ValueError(res.message)\n",
    "                \n",
    "            FPs_med.append(fitted_params[0]) # Add label to array for each DS median\n",
    "            FPs_disp.append(fitted_params[1])\n",
    "                \n",
    "#             df_fitted_params=pd.DataFrame(fitted_params)\n",
    "#             df33=df_fitted_params\n",
    "#             for i in range(1,100):\n",
    "#             df_fitted_params = pd.concat([df_fitted_params,df33], axis=1)\n",
    "\n",
    "            # Creating fitted fragility points from fitted parameters for the curve\n",
    "            yy=[]\n",
    "            for i in range(0,len(df4)):\n",
    "                yy.append(stats.norm.cdf(math.log(aa[i]),loc=math.log(fitted_params[0]),scale=fitted_params[1]))\n",
    "            ######################################################################  \n",
    "            df4['Fitted_Values_CDS_'+str(DS)]=yy # Adding column to dataframe\n",
    "            # THE ABOVE ALSO CONTAINS RELATIONSHIPS \n",
    "        ######################################################################   \n",
    "            \n",
    "\n",
    "            #ax.plot('Aggregate Liquefaction Hazard', 'Fitted_Values_CDS_'+str(DS), 'k-', label=str(category)+' '+str(DS)+' Fitted',data=df4)\n",
    "            #ax.plot('Bin_Avg', str(category)+'_CDS_'+str(DS)+'_Observed','k+', markersize=16,\n",
    "                    #label=str(category)+' '+str(DS)+' Observed',data=df5)\n",
    "\n",
    "            #print(df4['Fitted_Values_CDS_1'])\n",
    "#         ax.plot('Aggregate Liquefaction Hazard', 'Fitted_Values_CDS_1', 'k:', label=str(category)+' 1'+' Fitted',data=df4)\n",
    "#         ax.plot('Bin_Avg', str(category)+'_CDS_1'+'_Observed','kd', markersize=10, markerfacecolor='none',\n",
    "#                 label=str(category)+' 1'+' Observed',data=df5)\n",
    "\n",
    "#         ax.plot('Aggregate Liquefaction Hazard', 'Fitted_Values_CDS_2', 'k-', label=str(category)+' 2'+' Fitted',data=df4)\n",
    "#         ax.plot('Bin_Avg', str(category)+'_CDS_2'+'_Observed','k+', mfc='none', markersize=16,\n",
    "#                label=str(category)+' 2'+' Observed',data=df5) # DS_1 observed\n",
    "\n",
    "#         ax.plot('Aggregate Liquefaction Hazard', 'Fitted_Values_CDS_3', 'k--', label=str(category)+' 3'+' Fitted',data=df4)\n",
    "#         ax.plot('Bin_Avg', str(category)+'_CDS_3'+'_Observed','ko', markersize=10, markerfacecolor='none',\n",
    "#                 label=str(category)+' 3'+' Observed',data=df5)\n",
    "\n",
    "#         ax.plot('Aggregate Liquefaction Hazard', 'Fitted_Values_CDS_4', 'k-.', label=str(category)+' 4'+' Fitted',data=df4)\n",
    "#         ax.plot('Bin_Avg', str(category)+'_CDS_4'+'_Observed','kx', mfc='none', markersize=10,\n",
    "#                label=str(category)+' 4'+' Observed',data=df5) # DS_1 observed\n",
    "\n",
    "#         ax.plot('Aggregate Liquefaction Hazard', 'Fitted_Values_CDS_5', 'k:', label=str(category)+' 5'+' Fitted',data=df4)\n",
    "#         ax.plot('Bin_Avg', str(category)+'_CDS_5'+'_Observed','k*', mfc='none', markersize=10,\n",
    "#                label=str(category)+' 5'+' Observed',data=df5) # DS_1 observed\n",
    "\n",
    "#         plt.xlabel('Aggregate Liquefaction Hazard Bin Average', fontsize=10,**csfont)\n",
    "#         plt.ylabel('Probability of Exceeding Damage State Thresholds', fontsize=10,**csfont)\n",
    "#         plt.legend(loc='upper left', fontsize='8')\n",
    "\n",
    "#         fmt = '{x:,.0f}'\n",
    "#         tick = mtick.StrMethodFormatter(fmt)\n",
    "#         ax.xaxis.set_major_formatter(tick)\n",
    "#         plt.xticks([1,10,100,1000],**csfont)\n",
    "#             # For ticks, need max to be one unit higher than the value I actually want\n",
    "#         plt.ylim(-0.05, 1.05)\n",
    "#         plt.yticks(np.arange(0, 1.2, 0.2),**csfont)\n",
    "#         plt.grid(linestyle='-', linewidth='0.5')\n",
    "         #plt.savefig('HtotCostFxns_5Levs_'+str(category)+'.png',format=\"PNG\",dpi=500,bbox_inches=\"tight\")\n",
    "        \n",
    "        FPs_med_all.insert (iii, iii, FPs_med) # Insert fitted parameters median dataframe to all dataframe at column iii, labelled as iii\n",
    "        FPs_disp_all.insert (iii, iii, FPs_disp) # Insert fitted parameters median dataframe to all dataframe at column iii, labelled as iii\n",
    "\n",
    "    g_2('Total') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "second-quarter",
   "metadata": {},
   "source": [
    "Find a way to set up the above lines in an order which lets damage states be seen clearly and iterations be seen clearly\n",
    "Row 0s for medians, row 1s for dispersions\n",
    "Column 0 through 1000 for iterations\n",
    "Maybe create in different dataframes and append again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "minor-diesel",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "streaming-basketball",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[4,'location']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "occupied-toddler",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['location'][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "colonial-paste",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"gfailruns_allevents_forAlex_v2.4.csv\") # Import CSV of Name, TLSE, Building level, Transportation Level, Utilities Level\n",
    "df = df.dropna(subset=['Buildings_Cost']) # Drop rows where DS is No Value for Buildings (should be same rows for Transportation and Utilities)\n",
    "df.drop(df[df['American?'] == 0].index, inplace=True) # Dropping non-American events\n",
    "df.drop(df[df['PH_LQ'] == 0].index, inplace=True) # Dropping non-LSE events\n",
    "df.drop(df[df['PH_LQ'] == np.float('inf')].index, inplace=True) # Dropping allegedly infinite 2004 Pakistan event\n",
    "len(df)\n",
    "df7 = pd.DataFrame() # Establishing empty dataframe for each event's Htot / PopExp draws\n",
    "\n",
    "for ii in range(0,len(df)):\n",
    "    a = df.iloc[ii,9] # Htot Beta distribution shape parameter a, column name PH_LQ\n",
    "    b = df.iloc[ii,10] # Htot Beta distribution shape parameter b, column name QH_LQ\n",
    "    r = beta.rvs(a, b, size=1000) # Random selection of 1000 values from the beta distribution using parameters, a and b\n",
    "                                    # This sampling is instantaneous for all 46 events\n",
    "    r=r*df.iloc[ii,22] # Multiplying each selection by HlimLQ to get actual draw which we will work with\n",
    "\n",
    "    df7 = df7.append(pd.DataFrame(r).T) # Appending row of Htot / PopExp draws to previously empty DataFrame\n",
    "    \n",
    "    fig, ax = plt.subplots(1, 1)\n",
    "    ax.hist(r, histtype='stepfilled', alpha=0.2, bins=20)\n",
    "    #print(\"Completed \", ii)\n",
    "    \n",
    "    plt.xlabel('Aggregate Liquefaction Hazard Bin Average', fontsize=14)\n",
    "    plt.ylabel('Number of Draws', fontsize=14)\n",
    "    #plt.title(df.loc[ii,'location'], fontsize=18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "naked-budapest",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"gfailruns_allevents_forAlex_v2.4.csv\") # Import CSV of Name, TLSE, Building level, Transportation Level, Utilities Level\n",
    "df = df.dropna(subset=['Buildings_Cost']) # Drop rows where DS is No Value for Buildings (should be same rows for Transportation and Utilities)\n",
    "df.drop(df[df['American?'] == 0].index, inplace=True) # Dropping non-American events\n",
    "df.drop(df[df['PH_LQ'] == 0].index, inplace=True) # Dropping non-LSE events\n",
    "df.drop(df[df['PH_LQ'] == np.float('inf')].index, inplace=True) # Dropping allegedly infinite 2004 Pakistan event\n",
    "\n",
    "df7 = pd.DataFrame() # Establishing empty dataframe for each event's Htot / PopExp draws\n",
    "\n",
    "for ii in range(0,8):#,len(df)):\n",
    "    a = df.iloc[ii,9] # Htot Beta distribution shape parameter a, column name PH_LQ\n",
    "    b = df.iloc[ii,10] # Htot Beta distribution shape parameter b, column name QH_LQ\n",
    "    r = beta.rvs(a, b, size=1000) # Random selection of 1000 values from the beta distribution using parameters, a and b\n",
    "                                    # This sampling is instantaneous for all 46 events\n",
    "    r=r*df.iloc[ii,22] # Multiplying each selection by HlimLQ to get actual draw which we will work with\n",
    "\n",
    "    df7 = df7.append(pd.DataFrame(r).T) # Appending row of Htot / PopExp draws to previously empty DataFrame\n",
    "    \n",
    "    fig, ax = plt.subplots(1, 1)\n",
    "    ax.hist(r, histtype='stepfilled', alpha=0.2)\n",
    "    #print(\"Completed \", ii)\n",
    "    \n",
    "    plt.xlabel('Aggregate Liquefaction Hazard Bin Average', fontsize=14)\n",
    "    plt.ylabel('Number of Draws', fontsize=14)\n",
    "    plt.title(df['location'][ii], fontsize=18)\n",
    "    \n",
    "    #plt.savefig('PugetSound1965Hist.png',format=\"PNG\",dpi=500,bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "amazing-python",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"gfailruns_allevents_forAlex_v2.4.csv\") # Import CSV of Name, TLSE, Building level, Transportation Level, Utilities Level\n",
    "df = df.dropna(subset=['Buildings_Cost']) # Drop rows where DS is No Value for Buildings (should be same rows for Transportation and Utilities)\n",
    "df.drop(df[df['American?'] == 0].index, inplace=True) # Dropping non-American events\n",
    "df.drop(df[df['PH_LQ'] == 0].index, inplace=True) # Dropping non-LSE events\n",
    "df.drop(df[df['PH_LQ'] == np.float('inf')].index, inplace=True) # Dropping allegedly infinite 2004 Pakistan event\n",
    "\n",
    "df7 = pd.DataFrame() # Establishing empty dataframe for each event's Htot / PopExp draws\n",
    "\n",
    "for ii in range(0,len(df)):\n",
    "    a = df.iloc[ii,9] # Htot Beta distribution shape parameter a, column name PH_LQ\n",
    "    b = df.iloc[ii,10] # Htot Beta distribution shape parameter b, column name QH_LQ\n",
    "    r = beta.rvs(a, b, size=1000) # Random selection of 1000 values from the beta distribution using parameters, a and b\n",
    "                                    # This sampling is instantaneous for all 46 events\n",
    "    r=r*df.iloc[ii,22] # Multiplying each selection by HlimLQ to get actual draw which we will work with\n",
    "\n",
    "    df7 = df7.append(pd.DataFrame(r).T) # Appending row of Htot / PopExp draws to previously empty DataFrame\n",
    "    \n",
    "#     fig, ax = plt.subplots(1, 1)\n",
    "#     ax.hist(r, histtype='stepfilled', alpha=0.2)\n",
    "#     #print(\"Completed \", ii)\n",
    "    \n",
    "#     plt.xlabel('Aggregate Liquefaction Hazard Bin Average', fontsize=14)\n",
    "#     plt.ylabel('Number of Draws', fontsize=14)\n",
    "    \n",
    "#     plt.savefig('PugetSound1965Hist.png',format=\"PNG\",dpi=500,bbox_inches=\"tight\")\n",
    "\n",
    "df6 = pd.DataFrame(df['eventcode']) # Establishing dataframe of eventcodes\n",
    "df6.reset_index(drop=True, inplace=True) # Resetting index for df6\n",
    "df7.reset_index(drop=True, inplace=True) # Resetting index for df7\n",
    "#df7.insert (0, \"eventcode\", df6) # Adding dataframe of eventcodes to add to Htot / PopExp draws to identify events\n",
    "\n",
    "global FPs_med_all # setting variables to be used throughout the function\n",
    "global FPs_disp_all\n",
    "FPs_med_all = pd.DataFrame() # Creating empty DataFrames to be filled at end of function\n",
    "FPs_disp_all = pd.DataFrame()\n",
    "\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "for iii in range(0,df7.shape[1]): # For every iteration column in the DataFrame, df7\n",
    "    df = df.drop('HaggLQ', 1) # Dropping HaggLQ column\n",
    "    df8 = pd.DataFrame(df7.iloc[0:df7.shape[0],iii]) # Create a new DataFrame of only that column\n",
    "    #df8.insert (0, \"eventcode\", df6) \n",
    "    df.insert (5, \"HaggLQ\", df8)# Adding dataframe of eventcodes to add to Htot / PopExp draws to identify events\n",
    "    \n",
    "    part_2(df,iii)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "direct-brazil",
   "metadata": {},
   "outputs": [],
   "source": [
    "damage_cut_labels=[1,2,3,4,5]\n",
    "jjjj_med=[] # Create empty array for row names to be added into\n",
    "jjjj_disp=[] # Create empty array for row names to be added into\n",
    "for jjj in range(0,len(damage_cut_labels)): # Skipping over DS=0\n",
    "    jjjj_med.append(str('DS')+str(damage_cut_labels[jjj])+str('_med')) # Add label to array for each DS median\n",
    "    jjjj_disp.append(str('DS')+str(damage_cut_labels[jjj])+str('_disp')) # Add label to array for each DS dispersion\n",
    "    \n",
    "FPs_med_all.index=jjjj_med # Assign DataFrame index as values from the above array\n",
    "FPs_disp_all.index=jjjj_disp # Assign DataFrame index as values from the above array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "filled-instrument",
   "metadata": {},
   "outputs": [],
   "source": [
    "FPs_med_all.to_csv('FPs_med_all.csv') # Saving Htot five DS values under the same name, including index\n",
    "FPs_disp_all.to_csv('FPs_disp_all.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
